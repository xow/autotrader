Reddit thread

- Qwen Coder 14B Q8_0 (32K context)
- CodeGeeX4 ALL 9B Q8_0 (128K context)
- Yi Coder 9B Chat Q8_0 (128K context)

Main website https://docs.continue.dev/customize/model-roles/chat#local-offline-experience

If your local machine can run an 8B parameter model, then we recommend running Llama 3.1 8B on your machine
If your local machine can run a 16B parameter model, then we recommend running DeepSeek Coder 2 16B